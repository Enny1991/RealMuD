{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import argparse\n",
    "import time\n",
    "import cv2\n",
    "\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torchvision\n",
    "\n",
    "import os\n",
    "# from pytorch2caffe import pytorch2caffe, plot_graph\n",
    "import numpy as np\n",
    "\n",
    "import IPython.display as ipd\n",
    "\n",
    "from data_utils import MudNoise\n",
    "from model_stft import Mud, Mudv3, Mudv4, Mudv4noFFT, Mudv5noFFT, Mudv5LSTMnoFFT, Mudv5FFnoFFT\n",
    "import json\n",
    "import os\n",
    "import torch\n",
    "import time\n",
    "from torch import nn\n",
    "from torch.autograd import Variable\n",
    "import csv\n",
    "from ConvertModel import ConvertModel_caffe\n",
    "import onnx\n",
    "import caffe2.python.onnx.backend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NFFT IS: 512\n"
     ]
    }
   ],
   "source": [
    "# LSTM\n",
    "pytorch_net = Mudv5LSTMnoFFT(n_fft=512)\n",
    "dummy_input = torch.randn(1, 257, 61, 2)\n",
    "torch.onnx.export(pytorch_net, dummy_input, \"mudv5_lstm.onnx\", verbose=False)\n",
    "\n",
    "img = np.random.randn(1, 257, 61, 2).astype(np.float32)\n",
    "# Load the ONNX model\n",
    "model = onnx.load('mudv5_lstm.onnx')\n",
    "outputs = caffe2.python.onnx.backend.run_model(model, [img])\n",
    "print(outputs[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NFFT IS: 512\n",
      "Receptive field TIME: 253 samples.\n",
      "Receptive field FREQ: 253 samples.\n",
      "(1, 257, 1, 61)\n"
     ]
    }
   ],
   "source": [
    "# CNN\n",
    "pytorch_net = Mudv5noFFT(n_fft=512, bn_ch=16, layers=6)\n",
    "dummy_input = torch.randn(1, 2, 257, 61)\n",
    "torch.onnx.export(pytorch_net, dummy_input, \"mudv5_cnn_6_c_16.onnx\", verbose=False)\n",
    "\n",
    "img = np.random.randn(1, 2, 257, 61).astype(np.float32)\n",
    "model = onnx.load('mudv5_cnn_6_c_8.onnx')\n",
    "outputs = caffe2.python.onnx.backend.run_model(model, [img])\n",
    "print(outputs[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 257, 1, 1, 61)\n"
     ]
    }
   ],
   "source": [
    "# FF\n",
    "pytorch_net = Mudv5FFnoFFT(n_fft=512)\n",
    "dummy_input = torch.randn(1, 61, 257)\n",
    "torch.onnx.export(pytorch_net, dummy_input, \"mudv5_ff.onnx\", verbose=False)\n",
    "\n",
    "img = np.random.randn(1, 61, 257).astype(np.float32)\n",
    "model = onnx.load('mudv5_ff.onnx')\n",
    "outputs = caffe2.python.onnx.backend.run_model(model, [img])\n",
    "print(outputs[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def load_mask_model(load, base_dir='.'):\n",
    "#     json_dir = base_dir + '/exp/' + load\n",
    "#     with open(json_dir + '/architecture.json', 'r') as fff:\n",
    "#         p = json.load(fff)\n",
    "#         load_path = json_dir + '/net/' + 'cv/'\n",
    "\n",
    "#         model = Mudv5noFFT(n_fft=p['nfft'], kernel=(p['kernel1'], p['kernel2']), causal=p['causal'],\n",
    "#                                 layers=p['layers'], stacks=p['stacks'], verbose=False)\n",
    "\n",
    "#         mdl_idx = sorted([int(l.split('_')[-1].split('.')[0]) for l in os.listdir(load_path)])[-1]\n",
    "\n",
    "#         model.load_state_dict(torch.load(load_path + 'model_weight_{}.pt'.format(mdl_idx)))\n",
    "#         _ = model.eval()\n",
    "#         return model, p\n",
    "\n",
    "# pytorch_net, _ = load_mask_model('201903154220_Mudv5_512_4_NC')\n",
    "pytorch_net = Mudv5noFFT(layers=6)\n",
    "dummy_input = torch.randn(1, 2, 257, 61)\n",
    "\n",
    "torch.onnx.export(pytorch_net, dummy_input, \"mudv5_6l.onnx\", verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cv2.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = cv2.dnn.readNetFromONNX('./mudv5_lstm.onnx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.setInput(np.random.rand(1, 2, 257, 61))\n",
    "st = time.time()\n",
    "mask = net.forward()\n",
    "print(time.time() - st)\n",
    "mask.shape\n",
    "\n",
    "st = time.time()\n",
    "mask = pytorch_net(dummy_input)\n",
    "print(time.time() - st)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "causal = True\n",
    "size = 3\n",
    "dilation = 2 ** 3\n",
    "c = nn.Conv2d(10, 10, (size, size), stride=1, padding=((dilation*(size-1)//2), (dilation*(size-1)) if causal else (dilation*(size-1)//2)),\n",
    "                                dilation=dilation)\n",
    "\n",
    "a = torch.zeros(1, 10, 257, 128)\n",
    "a[:, :, 100:200, 100] = 1.\n",
    "\n",
    "d = c(a)\n",
    "d = d[:,:,:, :a.shape[-1]]\n",
    "print(d.shape)\n",
    "\n",
    "fig, ax = plt.subplots(2, 1)\n",
    "\n",
    "ax[0].imshow(a[0, 0].data.numpy(), aspect='auto')\n",
    "ax[1].imshow(d[0, 0].data.numpy(), aspect='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class slstm(nn.Module):\n",
    "    def __init__(self, n_fft=256, hop=125, n_hid=256, n_hid_ff=513, verbose=True):\n",
    "        super(slstm, self).__init__()\n",
    "        if verbose:\n",
    "            print(\"NFFT IS: {}\".format(n_fft))\n",
    "        self.n_fft = (n_fft // 2 + 1)\n",
    "        self.FFT = n_fft\n",
    "        self.HOP = hop\n",
    "        \n",
    "        self.lstm = nn.LSTM(input_size=self.n_fft * 2, hidden_size=n_hid)\n",
    "        self.ff1 = nn.Linear(n_hid, n_hid_ff)\n",
    "        self.ff2 = nn.Linear(n_hid_ff, n_hid_ff)\n",
    "        self.ff3 = nn.Linear(n_hid_ff, self.n_fft)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "#         x_stft = x.permute(0, 2, 1, 3)  # (B, L, F, 2)\n",
    "\n",
    "#         x_input_lstm = x_stft.contiguous().view(x_stft.shape[0], x_stft.shape[1], -1)  # (B, L, F*2)\n",
    "\n",
    "        out_lstm, _ = self.lstm(x)  # (B, L, 256)\n",
    "        out_lstm2 = out_lstm.contiguous().permute(1, 0, 2)\n",
    "\n",
    "        out1 = torch.relu(self.ff1(out_lstm2))  # (B, L, 513)\n",
    "        out2 = torch.relu(self.ff2(out1))  # (B, L, 513)\n",
    "        out3 = torch.sigmoid(self.ff3(out2))  # (B, L, F)\n",
    "\n",
    "        mask_speech = out3.permute(0, 2, 1).unsqueeze(2).unsqueeze(2)  # B, F, 1, 1, T\n",
    "\n",
    "        return mask_speech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pytorch_net = slstm(n_fft=512)\n",
    "dummy_input = torch.randn(10, 1, 514)\n",
    "\n",
    "torch.onnx.export(pytorch_net, dummy_input, \"mudv5_lstm_test.onnx\", verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = cv2.dnn.readNetFromONNX('./mudv5_lstm_test.onnx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# onnx from keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = 10\n",
    "def RNN():\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(64, return_sequences=True, input_shape=[max_len, 256]))\n",
    "    model.add(Dense(256,name='FC1', use_bias=False))\n",
    "    model.add(Dense(10,name='FC2', use_bias=False))\n",
    "#     inputs = Input(name='inputs',shape=[max_len, 256])\n",
    "# #     layer = LSTM(64, return_sequences=True)(inputs)\n",
    "#     layer = Dense(256,name='FC1', use_bias=False)(inputs)\n",
    "# #     layer = Activation('relu')(layer)\n",
    "# #     layer = Dropout(0.5)(layer)\n",
    "#     layer = Dense(1,name='out_layer', use_bias=False)(layer)\n",
    "# #     layer = Activation('sigmoid')(layer)\n",
    "#     model = Model(inputs=inputs,outputs=layer)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.resnet50 import preprocess_input\n",
    "import keras2onnx\n",
    "import onnxruntime\n",
    "import onnx\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import LSTM, Activation, Dense, Dropout, Input, Embedding, GRU\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing import sequence\n",
    "from keras.utils import to_categorical\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "# image preprocessing\n",
    "# img_path = 'elephant.jpg'   # make sure the image is in img_path\n",
    "# img_size = 224\n",
    "# # img = image.load_img(img_path, target_size=(img_size, img_size))\n",
    "# x = np.random.rand(224, 224)\n",
    "# x = np.expand_dims(x, axis=0)\n",
    "# x = preprocess_input(x)\n",
    "\n",
    "# # load keras model\n",
    "# model = RNN()\n",
    "# model.compile(loss='binary_crossentropy',optimizer=RMSprop(),metrics=['accuracy'])\n",
    "# print(model.summary())\n",
    "# # convert to onnx model\n",
    "# onnx_model = keras2onnx.convert_keras(model, model.name)\n",
    "\n",
    "# onnx.save(onnx_model, './model_from_keras.onnx')\n",
    "# # runtime prediction\n",
    "# # content = onnx_model.SerializeToString()\n",
    "# # sess = onnxruntime.InferenceSession(content)\n",
    "# x = x if isinstance(x, list) else [x]\n",
    "# feed = dict([(input.name, x[n]) for n, input in enumerate(sess.get_inputs())])\n",
    "# pred_onnx = sess.run(None, feed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras import applications\n",
    "from keras import backend as K\n",
    "import tensorflow as tf\n",
    "\n",
    "K.set_learning_phase(0)  ##\n",
    "model = RNN()\n",
    "# model = applications.densenet.DenseNet121(input_shape=(224, 224, 3), weights='imagenet', include_top=True)\n",
    "sess = K.get_session()\n",
    "\n",
    "print(model.input, model.outputs)\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.tools import freeze_graph\n",
    "from tensorflow.python.tools import optimize_for_inference_lib\n",
    "\n",
    "MODEL_PATH = 'out'\n",
    "MODEL_NAME = 'test'\n",
    "input_node_name = 'lstm_2_input'\n",
    "output_node_name = 'FC2_1/MatMul'\n",
    "\n",
    "\n",
    "tf.train.write_graph(sess.graph_def, MODEL_PATH, f'{MODEL_NAME}_graph.pb', as_text=False)\n",
    "tf.train.write_graph(sess.graph_def, MODEL_PATH, f'{MODEL_NAME}_graph.pbtxt')\n",
    "tf.train.Saver().save(sess, f'{MODEL_PATH}/{MODEL_NAME}.chkp')\n",
    "\n",
    "freeze_graph.freeze_graph(f'{MODEL_PATH}/{MODEL_NAME}_graph.pbtxt',\n",
    "                          None, False,\n",
    "                          f'{MODEL_PATH}/{MODEL_NAME}.chkp',\n",
    "                          output_node_name,\n",
    "                          \"save/restore_all\",\n",
    "                          \"save/Const:0\",\n",
    "                          f'{MODEL_PATH}/frozen_{MODEL_NAME}.pb',\n",
    "                          True, \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = cv2.dnn.readNetFromONNX('./model_from_keras.onnx')\n",
    "net.setInput(np.random.rand(1, 10, 256).astype('float32'))\n",
    "# print(net.getFLOPS(8, (1, 10, 256)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = cv2.dnn.readNetFromTensorflow(f'{MODEL_PATH}/frozen_{MODEL_NAME}.pb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.setInput(np.random.rand(10, 256).astype('float32'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = net.forward()\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# with TF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.contrib import rnn\n",
    "import tensorflow as tf\n",
    "# Network Parameters\n",
    "num_input = 28 # MNIST data input (img shape: 28*28)\n",
    "timesteps = 28 # timesteps\n",
    "num_hidden = 128 # hidden layer num of features\n",
    "num_classes = 10 # MNIST total classes (0-9 digits)\n",
    "\n",
    "# tf Graph input\n",
    "X = tf.placeholder(\"float\", [None, timesteps, num_input])\n",
    "Y = tf.placeholder(\"float\", [None, num_classes])\n",
    "\n",
    "# Define weights\n",
    "weights = {\n",
    "    'out': tf.Variable(tf.random_normal([num_hidden, num_classes]))\n",
    "}\n",
    "biases = {\n",
    "    'out': tf.Variable(tf.random_normal([num_classes]))\n",
    "}\n",
    "\n",
    "\n",
    "def RNN(x, weights, biases):\n",
    "\n",
    "    # Prepare data shape to match `rnn` function requirements\n",
    "    # Current data input shape: (batch_size, timesteps, n_input)\n",
    "    # Required shape: 'timesteps' tensors list of shape (batch_size, n_input)\n",
    "\n",
    "    # Unstack to get a list of 'timesteps' tensors of shape (batch_size, n_input)\n",
    "    x = tf.unstack(x, timesteps, 1)\n",
    "\n",
    "    # Define a lstm cell with tensorflow\n",
    "    lstm_cell = rnn.LSTMBlockFusedCell(num_hidden, forget_bias=1.0)\n",
    "\n",
    "    # Get lstm cell output\n",
    "    outputs, states = rnn.static_rnn(lstm_cell, x, dtype=tf.float32)\n",
    "\n",
    "    # Linear activation, using rnn inner loop last output\n",
    "    return tf.matmul(outputs[-1], weights['out']) + biases['out']\n",
    "\n",
    "logits = RNN(X, weights, biases)\n",
    "\n",
    "output = tf.add(logits, 0, name='logits')\n",
    "\n",
    "\n",
    "# Initialize the variables (i.e. assign their default value)\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    " \n",
    "#Create a saver object which will save all the variables\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "feed_dict ={X: np.random.rand(10, timesteps, num_input), Y: np.random.rand(10, num_classes)}\n",
    "#Run the operation by feeding input\n",
    "print(sess.run(logits, feed_dict))\n",
    "#Prints 24 which is sum of (w1+w2)*b1 \n",
    " \n",
    "#Now, save the graph\n",
    "saver.save(sess, 'my_lstm_model', global_step=42)\n",
    "\n",
    "print([n.name for n in tf.get_default_graph().as_graph_def().node])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    " \n",
    "#Prepare to feed input, i.e. feed_dict and placeholders\n",
    "w1 = tf.placeholder(\"float\", name=\"w1\")\n",
    "w2 = tf.placeholder(\"float\", name=\"w2\")\n",
    "b1= tf.Variable(2.0,name=\"bias\")\n",
    "feed_dict ={w1:4,w2:8}\n",
    " \n",
    "#Define a test operation that we will restore\n",
    "w3 = tf.add(w1,w2)\n",
    "w4 = tf.multiply(w3,b1,name=\"op_to_restore\")\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    " \n",
    "#Create a saver object which will save all the variables\n",
    "saver = tf.train.Saver()\n",
    " \n",
    "#Run the operation by feeding input\n",
    "print(sess.run(w4,feed_dict))\n",
    "#Prints 24 which is sum of (w1+w2)*b1 \n",
    " \n",
    "#Now, save the graph\n",
    "saver.save(sess, 'my_test_model', global_step=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = 'frozen_inference_graph_dnn.pb'\n",
    "# net = cv2.dnn.readNet(model)\n",
    "net = cv2.dnn.readNetFromTensorflow(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnx\n",
    "import caffe2.python.onnx.backend\n",
    "\n",
    "# Prepare the inputs, here we use numpy to generate some random inputs for demo purpose\n",
    "import numpy as np\n",
    "img = np.random.randn(10, 1, 514).astype(np.float32)\n",
    "\n",
    "# Load the ONNX model\n",
    "model = onnx.load('mudv5_lstm_test.onnx')\n",
    "\n",
    "# Run the ONNX model with Caffe2\n",
    "# outputs = caffe2.python.onnx.backend.run_model(model, [img])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = caffe2.python.onnx.backend.run_model(model, [img])\n",
    "\n",
    "print(outputs[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "opencv",
   "language": "python",
   "name": "opencv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
