{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "%matplotlib inline\n",
    "import IPython.display as ipd\n",
    "\n",
    "import soundfile as sf\n",
    "import librosa\n",
    "from data_utils import MudNoise\n",
    "from model_stft import Mud, Mudv3, Mudv4, MudnoFFT\n",
    "import json\n",
    "import os\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.autograd import Variable\n",
    "import csv\n",
    "from sep_eval import sep_eval as se\n",
    "from librosa import stft\n",
    "plt.style.use('classic')\n",
    "from beamformers import beamformers as bf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datadir = '/Data/DATASETS/WSJ/mud_noise/'\n",
    "validation_data_path = datadir + 'cv/debug_mud_v1.h5'\n",
    "\n",
    "data_verbose = MudNoise(validation_data_path, noisedir='/Data/DATASETS/NoiseX/8k/', task='cv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_mask_model(load, base_dir='.'):\n",
    "    json_dir = base_dir + '/exp/' + load\n",
    "    with open(json_dir + '/architecture.json', 'r') as fff:\n",
    "        p = json.load(fff)\n",
    "        load_path = json_dir + '/net/' + 'cv/'\n",
    "\n",
    "        model = Mudv4(n_fft=p['nfft'], kernel=(p['kernel1'], p['kernel2']), causal=p['causal'],\n",
    "                                layers=p['layers'], stacks=p['stacks'], verbose=False)\n",
    "\n",
    "        mdl_idx = sorted([int(l.split('_')[-1].split('.')[0]) for l in os.listdir(load_path)])[-1]\n",
    "\n",
    "        model.load_state_dict(torch.load(load_path + 'model_weight_{}.pt'.format(mdl_idx)))\n",
    "        _ = model.eval()\n",
    "        return model, p\n",
    "\n",
    "# mdl, _ = load_mask_model('201903152913_Mudv4_NC_512_6')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mix, s1 = data_verbose[200]\n",
    "mix = Variable(mix[:6]).contiguous()\n",
    "# recon, mask, mask_noise, psd_speech, psd_noise = mdl(mix.unsqueeze(0))\n",
    "recon = mdl(mix.unsqueeze(0))\n",
    "\n",
    "# mask = mask.data.cpu().numpy()\n",
    "# print(mask.shape)\n",
    "# mask_noise = mask_noise.data.cpu().numpy()\n",
    "# print(mask_noise.shape)\n",
    "\n",
    "# psd_speech = psd_speech.data.cpu().numpy()\n",
    "# print(psd_speech.shape)\n",
    "# psd_noise = psd_noise.data.cpu().numpy()\n",
    "# print(psd_noise.shape)\n",
    "\n",
    "m = mix.data.cpu().numpy()\n",
    "s = s1.data.cpu().numpy()\n",
    "r = recon.squeeze().data.cpu().numpy()\n",
    "ipd.display(ipd.Audio(m, rate=8000))\n",
    "ipd.display(ipd.Audio(r, rate=8000))\n",
    "\n",
    "print(se.sdr(s[0], m[0]))\n",
    "print(se.sdr(r, s[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(4):\n",
    "#     X = np.log10(np.abs(librosa.stft(m[i])) + 1)[::-1]\n",
    "#     plt.imshow(X, aspect='auto', cmap='magma')\n",
    "#     plt.savefig('ex_mix_ch{}.pdf'.format(i))\n",
    "\n",
    "# plt.figure()\n",
    "# X = np.log10(np.abs(librosa.stft(r)) + 1)[::-1]\n",
    "# plt.imshow(X, aspect='auto', cmap='magma')\n",
    "# plt.savefig('ex_sep.pdf'.format(i))\n",
    "\n",
    "plt.figure()\n",
    "X = mask.squeeze()[::-1]\n",
    "plt.imshow(X, aspect='auto', cmap='magma')\n",
    "plt.savefig('ex_mask.pdf')\n",
    "\n",
    "plt.figure()\n",
    "X = mask_noise.squeeze()[::-1]\n",
    "plt.imshow(X, aspect='auto', cmap='magma')\n",
    "plt.savefig('ex_mask_noise.pdf')\n",
    "\n",
    "plt.figure()\n",
    "X = psd_noise.squeeze()[50, 0]\n",
    "plt.imshow(X, aspect='auto', cmap='magma')\n",
    "plt.savefig('ex_psd_noise.pdf')\n",
    "\n",
    "plt.figure()\n",
    "X = psd_speech.squeeze()[200, 0]\n",
    "plt.imshow(X, aspect='auto', cmap='magma')\n",
    "plt.savefig('ex_psd_speech.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(recon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (all files)\n",
    "all_files_names = []\n",
    "all_traces = []\n",
    "all_mics = []\n",
    "all_nspk = {}\n",
    "with open(\"/Data/Dropbox/cocoha_workshop_zh/cocoha_code/automated_exps/output_session2_15s.csv\", \"r\") as f:\n",
    "    reader = csv.reader(f, delimiter=\",\")\n",
    "    \n",
    "    for i, line in enumerate(reader):\n",
    "        all_nspk[line[0]] = int(line[-1])\n",
    "        all_traces.append(line[5:-1])\n",
    "        all_mics.append(line[1:5])\n",
    "        all_files_names.append(line[0])\n",
    "\n",
    "print(len(all_files_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_trigger_v2(x):\n",
    "    Y = x\n",
    "    X = stft(Y)\n",
    "    Y = np.log10(np.abs(X) ** 2 + 1e-8)\n",
    "    YY = np.sum(Y, 0)\n",
    "    n90 = np.percentile(YY, 65)\n",
    "    tr = np.where(YY >= n90)[0][0]\n",
    "    return tr * 512\n",
    "\n",
    "def allign(x, y):\n",
    "    corr = np.correlate(x - np.mean(x), y - np.mean(y), mode='full')\n",
    "    lag = corr.argmax() - (len(x) - 1)\n",
    "    _err_log = \"OK\"\n",
    "\n",
    "    if lag > 0:\n",
    "        x = x[lag:]\n",
    "        y = y[:-lag]\n",
    "    else:\n",
    "        x = x[:]\n",
    "        y = y[:]\n",
    "        _err_log = \"ERROR: lag {}\".format(lag)\n",
    "    return x, y, _err_log\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "name = '20190222101808'\n",
    "all_data = []\n",
    "t_in_secs = []\n",
    "fs = 8000\n",
    "for i in [5, 6, 7, 8]:\n",
    "#     _fs, _y = wavfile.read('../data_whisper/session2/test_%s_wh%d.wav' % (name, i))\n",
    "    _y, _fs = librosa.load('/Data/Dropbox/cocoha_workshop_zh/cocoha_code/data_whisper/session2/test_%s_wh%d.wav' % (name, i), sr=8000, mono=False)\n",
    "    _y = _y.T.astype('float32')\n",
    "    all_data.append(_y)\n",
    "    assert(_fs == fs)\n",
    "    t_in_secs.append(_y.shape[0] // fs)\n",
    "    print(\"%d: %d seconds\" % (i, _y.shape[0] // fs), end='\\t\\t')\n",
    "\n",
    "# n_spk = all_nspk[name]\n",
    "n_spk = 1\n",
    "# print(\"N SPK: {}\".format(n_spk))\n",
    "m_len = np.min([a.shape[0] for a in all_data])\n",
    "all_data_cut = [a[:m_len] for a in all_data]\n",
    "all_data_array = np.hstack(all_data_cut) #.astype('float32')\n",
    "\n",
    "\n",
    "t = np.arange(len(all_data_array[:, 0])) / fs\n",
    "\n",
    "for_trigger = all_data_array[:, 6]\n",
    "trigger = find_trigger_v2(for_trigger)\n",
    "noise_calib = all_data_array[:trigger]\n",
    "# noise_calib = NOISE_CALIB\n",
    "print(\"Noise {}    [MAX = 22s]\".format(len(noise_calib) // fs))\n",
    "calib1 = all_data_array[0 * fs + trigger: 10 * fs + trigger]\n",
    "calib2 = all_data_array[15 * fs + trigger: 25 * fs + trigger]\n",
    "calib3 = all_data_array[30 * fs + trigger: 40 * fs + trigger]\n",
    "calib4 = all_data_array[45 * fs + trigger: 55 * fs + trigger]\n",
    "\n",
    "rec = all_data_array[max((15 * n_spk), 30) * fs + trigger:]\n",
    "\n",
    "print(\"Removing trigger => [{} ~= {}]\".format(t_in_secs[0] - trigger // fs, max((15 * n_spk), 30) + 15))\n",
    "\n",
    "plt.plot(for_trigger[:trigger + 5 * fs])\n",
    "plt.plot([trigger, trigger], [np.min(for_trigger[:trigger + 5 * fs]), np.max(for_trigger[:trigger + 5 * fs])], 'g--')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IDX = 0\n",
    "n_ch = 8\n",
    "keys = list(data.keys())\n",
    "rec = data[keys[IDX]]['rec']\n",
    "calib_speech = data[keys[IDX]]['calib_voice']\n",
    "calib_noise = data[keys[IDX]]['calib_noise']\n",
    "print(data[keys[IDX]]['SNR'])\n",
    "mix = Variable(torch.from_numpy(rec.T[:n_ch])).contiguous()\n",
    "\n",
    "y_net = mdl(mix.unsqueeze(0)).squeeze().data.cpu().numpy()[:10 * fs]\n",
    "y_beam = bf.MB_MVDR(rec.T[:n_ch], noise=calib_noise.T[:n_ch], target=calib_speech.T[:n_ch], mask='IRM')[:10 * fs]\n",
    "y_beam_2 = bf.SDW_MWF(rec.T[:n_ch], noise=calib_noise.T[:n_ch], target=calib_speech.T[:n_ch])[:10 * fs]\n",
    "\n",
    "y = calib_speech[:, 0]\n",
    "noisy = rec[:10 * fs, 0]\n",
    "\n",
    "# calculate best correlation lag\n",
    "y_net, y_2, _ = allign(y_net, y)\n",
    "y_noisy, y_3, _ = allign(noisy, y)\n",
    "y_beam, y_4, _ = allign(y_beam, y)\n",
    "y_beam_2, y_5, _ = allign(y_beam_2, y)\n",
    "\n",
    "# SDR\n",
    "print(\"NET   : {:.4}\".format(se.sdr(y_net, y_2)))\n",
    "print(\"MB: {:.4}\".format(se.sdr(y_beam, y_4)))\n",
    "print(\"SDW: {:.4}\".format(se.sdr(y_beam_2, y_5)))\n",
    "print(\"NOISY : {:.4}\".format(se.sdr(y_noisy, y_3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28305\n",
      "18893\n",
      "28305\n",
      "18893\n"
     ]
    }
   ],
   "source": [
    "mdl1, _ = load_mask_model('201903152913_Mudv4_C_512_6')\n",
    "print(sum(p.numel() for p in mdl1.parameters() if p.requires_grad))\n",
    "mdl2, _ = load_mask_model('201903152912_Mudv4_C_512_4')\n",
    "print(sum(p.numel() for p in mdl2.parameters() if p.requires_grad))\n",
    "mdl3, _ = load_mask_model('201903152912_Mudv4_NC_512_6')\n",
    "print(sum(p.numel() for p in mdl3.parameters() if p.requires_grad))\n",
    "mdl4, _ = load_mask_model('201903152912_Mudv4_NC_512_4')\n",
    "print(sum(p.numel() for p in mdl4.parameters() if p.requires_grad))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mdl1, _ = load_mask_model('201903152913_Mudv4_C_512_6')\n",
    "mdl2, _ = load_mask_model('201903152912_Mudv4_C_512_4')\n",
    "mdl3, _ = load_mask_model('201903152912_Mudv4_NC_512_6')\n",
    "mdl4, _ = load_mask_model('201903152912_Mudv4_NC_512_4')\n",
    "\n",
    "models = [mdl1, mdl2, mdl3, mdl4, bf.MB_MVDR, bf.SDW_MWF]\n",
    "desc = ['C_512_6', 'C_512_4', 'NC_512_6', 'NC_512_4', 'MB_MVDR', 'SDW_MWF']\n",
    "m_type = ['n', 'n', 'n', 'n', 'm', 'b']\n",
    "\n",
    "keys = list(data.keys())\n",
    "\n",
    "with open('results_real_data_v1.csv', 'w') as csv_file:\n",
    "    file_writer = csv.writer(csv_file, delimiter=',')\n",
    "    \n",
    "    header = ['model', 'snr', 'n_ch', 'sdr', 'stoi']\n",
    "    file_writer.writerow(header)\n",
    "    \n",
    "    for IDX in range(60):\n",
    "        print(\"Sample: {}\".format(IDX))\n",
    "        rec = data[keys[IDX]]['rec'].T\n",
    "        calib_speech = data[keys[IDX]]['calib_voice'].T\n",
    "        calib_noise = data[keys[IDX]]['calib_noise'].T\n",
    "        snr = data[keys[IDX]]['SNR']\n",
    "        mix = Variable(torch.from_numpy(rec)).contiguous()\n",
    "        \n",
    "        for n_ch in [2, 4, 8, 12]:\n",
    "            print(\"\\tCH: {}\".format(n_ch))\n",
    "            for model, tp, i in zip(models, m_type, desc):\n",
    "                print(\"\\t\\tModel: {} ({})\".format(i, tp))\n",
    "                if tp == 'n':\n",
    "                    y_hat = model(mix.unsqueeze(0)[:, :n_ch]).squeeze().data.cpu().numpy()[:10 * fs]\n",
    "                elif tp == 'm':\n",
    "                    y_hat = model(rec[:n_ch], noise=calib_noise[:n_ch], target=calib_speech[:n_ch], mask='IRM')[:10 * fs]\n",
    "                else:\n",
    "                    y_hat = model(rec[:n_ch], noise=calib_noise[:n_ch], target=calib_speech[:n_ch])[:10 * fs]\n",
    "\n",
    "                y = calib_speech[0]\n",
    "\n",
    "                # calculate best correlation lag\n",
    "                y_hat, y_2, error = allign(y_hat, y)\n",
    "                print(\"\\t\\t\\tAllign: {}\".format(error))\n",
    "\n",
    "                # SDR\n",
    "                sdr = se.sdr(y_hat, y_2)\n",
    "                stoi = se.stoi(y_hat, y_2, fs=8000)\n",
    "\n",
    "                file_writer.writerow([i, snr, n_ch, sdr, stoi])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Try to load the full WHISPER dataset (ENH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_trigger_v2(x):\n",
    "    Y = x\n",
    "    X = stft(Y)\n",
    "    Y = np.log10(np.abs(X) ** 2 + 1e-8)\n",
    "    YY = np.sum(Y, 0)\n",
    "    n90 = np.percentile(YY, 65)\n",
    "    tr = np.where(YY >= n90)[0][0]\n",
    "    return tr * 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timestamps = []\n",
    "speakers = []\n",
    "valids = []\n",
    "all_nspk = {}\n",
    "all_snr = []\n",
    "\n",
    "with open(\"/Data/Dropbox/cocoha_workshop_zh/cocoha_code/automated_exps/output_session2_15s_only_enh.csv\", \"r\") as f:\n",
    "    reader = csv.reader(f, delimiter=\",\")\n",
    "    for i, line in enumerate(reader):\n",
    "        all_nspk[line[0]] = int(line[-1])\n",
    "        timestamps.append(line[0])\n",
    "        speakers.append(np.array(line[1:5]))\n",
    "        _traces = line[5:-1]\n",
    "        all_snr.append(line[-2].split('_')[3].split('SNR')[0])\n",
    "        valids.append(np.array(np.where(np.array(_traces) != '/Users/enea/DATASETS/Noise/silence.wav')[0]))\n",
    "print(all_snr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "all_samples = {}\n",
    "\n",
    "for name, snr in zip(timestamps, all_snr):\n",
    "    sample = {}\n",
    "    print(name)\n",
    "    all_data = []\n",
    "    t_in_secs = []\n",
    "    fs = 8000\n",
    "    for i in [5, 6, 7, 8]:\n",
    "        _y, _fs = librosa.load('/Data/Dropbox/cocoha_workshop_zh/cocoha_code/data_whisper/session2/test_%s_wh%d.wav' % (name, i), sr=8000, mono=False)\n",
    "        _y = _y.T.astype('float32')\n",
    "        all_data.append(_y)\n",
    "        assert(_fs == fs)\n",
    "        t_in_secs.append(_y.shape[0] // fs)\n",
    "#         print(\"%d: %d seconds\" % (i, _y.shape[0] // fs), end='\\t\\t')\n",
    "\n",
    "    n_spk = all_nspk[name]\n",
    "    m_len = np.min([a.shape[0] for a in all_data])\n",
    "    all_data_cut = [a[:m_len] for a in all_data]\n",
    "    all_data_array = np.hstack(all_data_cut) #.astype('float32')\n",
    "\n",
    "\n",
    "    t = np.arange(len(all_data_array[:, 0])) / fs\n",
    "\n",
    "    for_trigger = all_data_array[:, 6]\n",
    "    trigger = find_trigger_v2(for_trigger)\n",
    "    noise_calib = all_data_array[:trigger]\n",
    "    # noise_calib = NOISE_CALIB\n",
    "    print(\"\\tNoise {}    [MAX = 22s]\".format(len(noise_calib) // fs))\n",
    "    calib1 = all_data_array[0 * fs + trigger: 10 * fs + trigger]\n",
    "    calib2 = all_data_array[15 * fs + trigger: 25 * fs + trigger]\n",
    "    calib3 = all_data_array[30 * fs + trigger: 40 * fs + trigger]\n",
    "    calib4 = all_data_array[45 * fs + trigger: 55 * fs + trigger]\n",
    "    calib = [calib1, calib2]\n",
    "\n",
    "    rec = all_data_array[max((15 * n_spk), 30) * fs + trigger:]\n",
    "    \n",
    "    if any([c.shape[0] != 10 * fs for c in calib]) or rec.shape[0] < 10 * fs:\n",
    "        print('\\t!!!Check trigger!!!')\n",
    "        continue\n",
    "    \n",
    "    sample['rec'] = rec\n",
    "    sample['calib_voice'] = calib1\n",
    "    sample['calib_noise'] = calib2\n",
    "    sample['SNR'] = snr\n",
    "    \n",
    "    all_samples[name] = sample\n",
    "    \n",
    "    print(\"\\tRemoving trigger => [{} ~= {}]\".format(t_in_secs[0] - trigger // fs, max((15 * n_spk), 30) + 15))\n",
    "\n",
    "#     plt.plot(for_trigger[:trigger + 5 * fs])\n",
    "#     plt.plot([trigger, trigger], [np.min(for_trigger[:trigger + 5 * fs]), np.max(for_trigger[:trigger + 5 * fs])], 'g--')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pkl.dump(all_samples, open('session_2_enh.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mdl.cuda()\n",
    "s = all_samples[0]\n",
    "\n",
    "mix = Variable(torch.from_numpy(s['rec'].T[:8])).contiguous().cuda()\n",
    "recon = mdl(mix.unsqueeze(0))\n",
    "\n",
    "ipd.display(ipd.Audio(s['calib_voice'][:, 0], rate=8000))\n",
    "ipd.display(ipd.Audio(s['rec'][:, 0], rate=8000))\n",
    "ipd.display(ipd.Audio(recon.squeeze().data.cpu().numpy(), rate=8000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle as pkl\n",
    "\n",
    "data = pkl.load(open('session_2_enh.pkl', 'rb'))\n",
    "print(len(data))\n",
    "print(data.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200, 6, 32000)\n",
      "(200, 6, 32000)\n",
      "(200, 6, 32000)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "K = MudNoise('/Data/DATASETS/WSJ/mud_noise/cv/debug_mud_v1.h5', noisedir='/Data/DATASETS/NoiseX/8k/', task='cv', n_ch=6, verbose=True)\n",
    "\n",
    "A, B, C = [], [], []\n",
    "for i in range(200):\n",
    "    a, b, c = K[i]\n",
    "    A.append(a.unsqueeze(0))\n",
    "    B.append(b.unsqueeze(0))\n",
    "    C.append(c)\n",
    "\n",
    "_mix = torch.cat(A, 0)\n",
    "_s1 = torch.cat(B, 0)\n",
    "_n = np.array(C)\n",
    "\n",
    "rec = _mix.data.numpy()\n",
    "calib_speech = _s1.data.numpy()\n",
    "calib_noise = _n\n",
    "\n",
    "print(rec.shape)\n",
    "print(calib_speech.shape)\n",
    "print(calib_noise.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle as pkl\n",
    "d = pkl.load(open('debug.pkl', 'rb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/enea/anaconda3/envs/cuda10/lib/python3.7/site-packages/beamformers/beamformers.py:525: RuntimeWarning: divide by zero encountered in cdouble_scalars\n",
      "  h_r = (1. / _lambda) * _G[:, 0]\n",
      "/home/enea/anaconda3/envs/cuda10/lib/python3.7/site-packages/beamformers/beamformers.py:525: RuntimeWarning: invalid value encountered in cdouble_scalars\n",
      "  h_r = (1. / _lambda) * _G[:, 0]\n",
      "/home/enea/anaconda3/envs/cuda10/lib/python3.7/site-packages/beamformers/beamformers.py:525: RuntimeWarning: invalid value encountered in multiply\n",
      "  h_r = (1. / _lambda) * _G[:, 0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MB: nan\n",
      "SDW: 20.77\n"
     ]
    }
   ],
   "source": [
    "idx = 20\n",
    "# c_speech = calib_speech[idx]\n",
    "# c_noise = calib_noise[idx]\n",
    "# r = rec[idx]\n",
    "c_speech = d['y']\n",
    "c_noise = d['n']\n",
    "r = d['r']\n",
    "\n",
    "y_beam = bf.MB_MVDR(r, noise=c_noise, target=c_speech, mask='IBM')\n",
    "y_beam_2 = bf.SDW_MWF(r, noise=c_noise, target=c_speech)\n",
    "\n",
    "y = c_speech[0]\n",
    "\n",
    "# calculate best correlation lag\n",
    "y_beam, y_4, _ = allign(y_beam, y)\n",
    "y_beam_2, y_5, _ = allign(y_beam_2, y)\n",
    "\n",
    "# SDR\n",
    "print(\"MB: {:.4}\".format(se.sdr(y_beam, y_4)))\n",
    "print(\"SDW: {:.4}\".format(se.sdr(y_beam_2, y_5)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cuda10",
   "language": "python",
   "name": "cuda10"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
